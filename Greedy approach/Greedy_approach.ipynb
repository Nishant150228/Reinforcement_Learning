{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "af133bb3003e433db124cb478a9d0153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Start Warehouse Navigation",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_92849633aab04dc89f979377096b10da",
            "style": "IPY_MODEL_ec6f0bf9a7614f2ca62f9de6c916a0e6",
            "tooltip": ""
          }
        },
        "92849633aab04dc89f979377096b10da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6f0bf9a7614f2ca62f9de6c916a0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b0058d589dcc4618a010477ff0316111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Start Stock Trading",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_cbeb6fd0a6414ec998f37c959ea1f996",
            "style": "IPY_MODEL_e14d3cb0835e4738bda88015160feceb",
            "tooltip": ""
          }
        },
        "cbeb6fd0a6414ec998f37c959ea1f996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e14d3cb0835e4738bda88015160feceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBGaq9be4nYW",
        "outputId": "a25b9fd3-dff8-4eb9-9971-525b187408cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Warehouse Navigation Simulation\n",
            "\n",
            "[[0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: 1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: 1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: 10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "class WarehouseEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(WarehouseEnv, self).__init__()\n",
        "\n",
        "        # Define grid size and positions\n",
        "        self.grid_size = 10\n",
        "        self.robot_pos = [0, 0]  # Starting position of the robot\n",
        "        self.items = [[5, 5], [2, 8], [8, 3]]  # Positions of items\n",
        "\n",
        "        # Action space: 0 = Up, 1 = Down, 2 = Left, 3 = Right\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        # Observation space is the robot's position in the grid\n",
        "        self.observation_space = spaces.Box(low=0, high=self.grid_size - 1, shape=(2,), dtype=np.int32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.robot_pos = [0, 0]\n",
        "        self.items = [[5, 5], [2, 8], [8, 3]]  # Reset item positions\n",
        "        return np.array(self.robot_pos)\n",
        "\n",
        "    def step(self, action):\n",
        "        # Move robot based on action\n",
        "        if action == 0:   # Up\n",
        "            self.robot_pos[1] = max(0, self.robot_pos[1] - 1)\n",
        "        elif action == 1: # Down\n",
        "            self.robot_pos[1] = min(self.grid_size - 1, self.robot_pos[1] + 1)\n",
        "        elif action == 2: # Left\n",
        "            self.robot_pos[0] = max(0, self.robot_pos[0] - 1)\n",
        "        elif action == 3: # Right\n",
        "            self.robot_pos[0] = min(self.grid_size - 1, self.robot_pos[0] + 1)\n",
        "\n",
        "        reward = -0.1  # Slight penalty for movement\n",
        "        done = False\n",
        "\n",
        "        # Check if the robot is on an item\n",
        "        if self.robot_pos in self.items:\n",
        "            reward = 1  # Reward for reaching an item\n",
        "            self.items.remove(self.robot_pos)\n",
        "\n",
        "        if not self.items:  # If all items are picked up\n",
        "            done = True\n",
        "            reward = 10  # Large reward for completing task\n",
        "\n",
        "        return np.array(self.robot_pos), reward, done, {}\n",
        "\n",
        "    def render(self):\n",
        "        grid = np.zeros((self.grid_size, self.grid_size), dtype=int)\n",
        "        for item in self.items:\n",
        "            grid[item[1], item[0]] = 2  # Mark items with '2'\n",
        "        grid[self.robot_pos[1], self.robot_pos[0]] = 1  # Mark robot with '1'\n",
        "        print(grid)\n",
        "\n",
        "# Greedy policy function to choose action towards the closest item\n",
        "def greedy_policy(robot_pos, items):\n",
        "    if not items:\n",
        "        return random.choice([0, 1, 2, 3])\n",
        "\n",
        "    distances = [math.sqrt((item[0] - robot_pos[0]) ** 2 + (item[1] - robot_pos[1]) ** 2) for item in items]\n",
        "    closest_item = items[np.argmin(distances)]\n",
        "\n",
        "    # Choose action that minimizes distance to the closest item\n",
        "    if closest_item[0] > robot_pos[0]:\n",
        "        return 3  # Move Right\n",
        "    elif closest_item[0] < robot_pos[0]:\n",
        "        return 2  # Move Left\n",
        "    elif closest_item[1] > robot_pos[1]:\n",
        "        return 1  # Move Down\n",
        "    else:\n",
        "        return 0  # Move Up\n",
        "\n",
        "# Run the environment with the Greedy policy\n",
        "env = WarehouseEnv()\n",
        "state = env.reset()\n",
        "done = False\n",
        "\n",
        "print(\"Starting Warehouse Navigation Simulation\\n\")\n",
        "while not done:\n",
        "    action = greedy_policy(env.robot_pos, env.items)\n",
        "    state, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "    print(f\"Reward: {reward}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial Setup:\n",
        "\n",
        "The environment is initialized as a 10x10 grid.\n",
        "The robot starts at position\n",
        "[\n",
        "0\n",
        ",\n",
        "0\n",
        "]\n",
        "[0,0], and the items are placed at predefined positions:\n",
        "[\n",
        "[\n",
        "5\n",
        ",\n",
        "5\n",
        "]\n",
        ",\n",
        "[\n",
        "2\n",
        ",\n",
        "8\n",
        "]\n",
        ",\n",
        "[\n",
        "8\n",
        ",\n",
        "3\n",
        "]\n",
        "]\n",
        "[[5,5],[2,8],[8,3]].\n",
        "The goal is to collect all items by moving the robot to their positions.\n",
        "Greedy Policy:\n",
        "\n",
        "At each step, the greedy policy chooses the action that moves the robot closer to the nearest item.\n",
        "The distance to each item is calculated using the Euclidean distance formula:\n",
        "𝑑\n",
        "=\n",
        "(\n",
        "𝑥\n",
        "2\n",
        "−\n",
        "𝑥\n",
        "1\n",
        ")\n",
        "2\n",
        "+\n",
        "(\n",
        "𝑦\n",
        "2\n",
        "−\n",
        "𝑦\n",
        "1\n",
        ")\n",
        "2\n",
        "d=\n",
        "(x\n",
        "2\n",
        "​\n",
        " −x\n",
        "1\n",
        "​\n",
        " )\n",
        "2\n",
        " +(y\n",
        "2\n",
        "​\n",
        " −y\n",
        "1\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "​\n",
        "\n",
        "The item with the minimum distance is identified as the closest item.\n",
        "Action Selection:\n",
        "\n",
        "The greedy policy selects the action that minimizes the distance to the closest item:\n",
        "Move Right (3): If the item's x-coordinate is greater than the robot's x-coordinate.\n",
        "Move Left (2): If the item's x-coordinate is smaller than the robot's x-coordinate.\n",
        "Move Down (1): If the item's y-coordinate is greater than the robot's y-coordinate.\n",
        "Move Up (0): If the item's y-coordinate is smaller than the robot's y-coordinate.\n",
        "Reward Structure:\n",
        "\n",
        "The robot receives:\n",
        "-0.1 for each movement to encourage efficiency (penalty for unnecessary moves).\n",
        "+1 when it reaches an item.\n",
        "+10 when all items are collected, marking task completion.\n",
        "Termination Condition:\n",
        "\n",
        "The simulation ends when all items are collected (\n",
        "‘\n",
        "𝑑\n",
        "𝑜\n",
        "𝑛\n",
        "𝑒\n",
        "=\n",
        "𝑇\n",
        "𝑟\n",
        "𝑢\n",
        "𝑒\n",
        "‘\n",
        "‘done=True‘)."
      ],
      "metadata": {
        "id": "ibynBqd870Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from gym import spaces\n",
        "\n",
        "class StockTradingEnv(gym.Env):\n",
        "    def __init__(self, data):\n",
        "        super(StockTradingEnv, self).__init__()\n",
        "\n",
        "        self.data = data\n",
        "        self.current_step = 0\n",
        "        self.balance = 1000  # Initial balance\n",
        "        self.position = 0  # Stock position (number of stocks held)\n",
        "        self.net_worth = self.balance\n",
        "        self.max_steps = len(data) - 1\n",
        "\n",
        "        # Action space: 0 = Hold, 1 = Buy, 2 = Sell\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # Observation space includes stock price and net worth\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(2,), dtype=np.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.balance = 1000\n",
        "        self.position = 0\n",
        "        self.net_worth = self.balance\n",
        "        return self._next_observation()\n",
        "\n",
        "    def _next_observation(self):\n",
        "        current_price = self.data[self.current_step]\n",
        "        return np.array([current_price, self.net_worth])\n",
        "\n",
        "    def step(self, action):\n",
        "        current_price = self.data[self.current_step]\n",
        "\n",
        "        if action == 1:  # Buy\n",
        "            self.position += self.balance // current_price\n",
        "            self.balance %= current_price\n",
        "        elif action == 2 and self.position > 0:  # Sell\n",
        "            self.balance += self.position * current_price\n",
        "            self.position = 0\n",
        "\n",
        "        self.net_worth = self.balance + self.position * current_price\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "        reward = self.net_worth - 1000  # Reward is change in net worth\n",
        "\n",
        "        return self._next_observation(), reward, done, {}\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"Step: {self.current_step}, Balance: {self.balance}, Position: {self.position}, Net Worth: {self.net_worth}\")\n",
        "\n",
        "# Sample data for stock prices\n",
        "data = np.random.normal(100, 10, 100)\n",
        "\n",
        "env = StockTradingEnv(data)\n",
        "state = env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = random.choice([0, 1, 2])  # Greedy action can be applied here with a real strategy\n",
        "    state, reward, done, info = env.step(action)\n",
        "    env.render()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDAsci7v5B-L",
        "outputId": "86eda668-e7c8-49d7-8b65-e253a840718d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1, Balance: 1000, Position: 0, Net Worth: 1000.0\n",
            "Step: 2, Balance: 1000, Position: 0, Net Worth: 1000.0\n",
            "Step: 3, Balance: 1000, Position: 0, Net Worth: 1000.0\n",
            "Step: 4, Balance: 1000, Position: 0, Net Worth: 1000.0\n",
            "Step: 5, Balance: 1000, Position: 0, Net Worth: 1000.0\n",
            "Step: 6, Balance: 96.75362658816596, Position: 8.0, Net Worth: 1000.0\n",
            "Step: 7, Balance: 96.75362658816596, Position: 8.0, Net Worth: 1001.9787899237039\n",
            "Step: 8, Balance: 96.75362658816596, Position: 8.0, Net Worth: 933.4670706055146\n",
            "Step: 9, Balance: 96.75362658816596, Position: 8.0, Net Worth: 869.5517889461931\n",
            "Step: 10, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 833.7710905821799\n",
            "Step: 11, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 872.1427698208875\n",
            "Step: 12, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 1131.9791757565313\n",
            "Step: 13, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 1059.2857373715924\n",
            "Step: 14, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 850.6710665847318\n",
            "Step: 15, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 775.2596032399716\n",
            "Step: 16, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 868.4596483682735\n",
            "Step: 17, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 881.1154482667245\n",
            "Step: 18, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 869.8025511523157\n",
            "Step: 19, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 907.0535059257752\n",
            "Step: 20, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 881.4007192579579\n",
            "Step: 21, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 900.216754536705\n",
            "Step: 22, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 1037.888308993723\n",
            "Step: 23, Balance: 4.6264435889142135, Position: 9.0, Net Worth: 930.7525615312313\n",
            "Step: 24, Balance: 844.0968746681734, Position: 0, Net Worth: 844.0968746681734\n",
            "Step: 25, Balance: 844.0968746681734, Position: 0, Net Worth: 844.0968746681734\n",
            "Step: 26, Balance: 15.398456296586517, Position: 9.0, Net Worth: 844.0968746681735\n",
            "Step: 27, Balance: 15.398456296586517, Position: 9.0, Net Worth: 1039.0028066963678\n",
            "Step: 28, Balance: 15.398456296586517, Position: 9.0, Net Worth: 957.9824058459865\n",
            "Step: 29, Balance: 15.398456296586517, Position: 9.0, Net Worth: 924.2454583013862\n",
            "Step: 30, Balance: 942.1711425764929, Position: 0, Net Worth: 942.1711425764929\n",
            "Step: 31, Balance: 76.20685595333748, Position: 8.0, Net Worth: 942.1711425764929\n",
            "Step: 32, Balance: 751.3759939938138, Position: 0, Net Worth: 751.3759939938138\n",
            "Step: 33, Balance: 751.3759939938138, Position: 0, Net Worth: 751.3759939938138\n",
            "Step: 34, Balance: 751.3759939938138, Position: 0, Net Worth: 751.3759939938138\n",
            "Step: 35, Balance: 751.3759939938138, Position: 0, Net Worth: 751.3759939938138\n",
            "Step: 36, Balance: 81.10980300661868, Position: 8.0, Net Worth: 751.3759939938138\n",
            "Step: 37, Balance: 0.9966408207895796, Position: 9.0, Net Worth: 722.0151004932515\n",
            "Step: 38, Balance: 0.9966408207895796, Position: 9.0, Net Worth: 1027.9003476441549\n",
            "Step: 39, Balance: 0.9966408207895796, Position: 9.0, Net Worth: 939.1246562311575\n",
            "Step: 40, Balance: 845.9908093784287, Position: 0, Net Worth: 845.9908093784287\n",
            "Step: 41, Balance: 845.9908093784287, Position: 0, Net Worth: 845.9908093784287\n",
            "Step: 42, Balance: 845.9908093784287, Position: 0, Net Worth: 845.9908093784287\n",
            "Step: 43, Balance: 845.9908093784287, Position: 0, Net Worth: 845.9908093784287\n",
            "Step: 44, Balance: 38.23016312578204, Position: 8.0, Net Worth: 845.9908093784287\n",
            "Step: 45, Balance: 934.2021104175261, Position: 0, Net Worth: 934.2021104175261\n",
            "Step: 46, Balance: 6.940729683450712, Position: 9.0, Net Worth: 934.2021104175261\n",
            "Step: 47, Balance: 6.940729683450712, Position: 9.0, Net Worth: 887.6089826237411\n",
            "Step: 48, Balance: 6.940729683450712, Position: 9.0, Net Worth: 918.8759716977368\n",
            "Step: 49, Balance: 6.940729683450712, Position: 9.0, Net Worth: 817.52589359952\n",
            "Step: 50, Balance: 915.0591558618331, Position: 0, Net Worth: 915.0591558618331\n",
            "Step: 51, Balance: 915.0591558618331, Position: 0, Net Worth: 915.0591558618331\n",
            "Step: 52, Balance: 915.0591558618331, Position: 0, Net Worth: 915.0591558618331\n",
            "Step: 53, Balance: 58.09814149171186, Position: 9.0, Net Worth: 915.0591558618331\n",
            "Step: 54, Balance: 58.09814149171186, Position: 9.0, Net Worth: 752.0003528950141\n",
            "Step: 55, Balance: 58.09814149171186, Position: 9.0, Net Worth: 814.3686657603473\n",
            "Step: 56, Balance: 58.09814149171186, Position: 9.0, Net Worth: 1013.444943696395\n",
            "Step: 57, Balance: 58.09814149171186, Position: 9.0, Net Worth: 966.1186271229748\n",
            "Step: 58, Balance: 58.09814149171186, Position: 9.0, Net Worth: 980.5612133645543\n",
            "Step: 59, Balance: 58.09814149171186, Position: 9.0, Net Worth: 1036.707481146953\n",
            "Step: 60, Balance: 58.09814149171186, Position: 9.0, Net Worth: 992.5166415856592\n",
            "Step: 61, Balance: 58.09814149171186, Position: 9.0, Net Worth: 918.3391629265527\n",
            "Step: 62, Balance: 58.09814149171186, Position: 9.0, Net Worth: 957.7858856214502\n",
            "Step: 63, Balance: 58.09814149171186, Position: 9.0, Net Worth: 955.8408102362124\n",
            "Step: 64, Balance: 58.09814149171186, Position: 9.0, Net Worth: 810.3507083714563\n",
            "Step: 65, Balance: 58.09814149171186, Position: 9.0, Net Worth: 1028.4594722353258\n",
            "Step: 66, Balance: 58.09814149171186, Position: 9.0, Net Worth: 801.972997753561\n",
            "Step: 67, Balance: 58.09814149171186, Position: 9.0, Net Worth: 958.8456667268013\n",
            "Step: 68, Balance: 1082.0416866081473, Position: 0, Net Worth: 1082.0416866081473\n",
            "Step: 69, Balance: 1082.0416866081473, Position: 0, Net Worth: 1082.0416866081473\n",
            "Step: 70, Balance: 1082.0416866081473, Position: 0, Net Worth: 1082.0416866081473\n",
            "Step: 71, Balance: 1082.0416866081473, Position: 0, Net Worth: 1082.0416866081473\n",
            "Step: 72, Balance: 75.28487986078574, Position: 10.0, Net Worth: 1082.0416866081473\n",
            "Step: 73, Balance: 75.28487986078574, Position: 10.0, Net Worth: 978.3044045977368\n",
            "Step: 74, Balance: 1045.8769614596035, Position: 0, Net Worth: 1045.8769614596035\n",
            "Step: 75, Balance: 1045.8769614596035, Position: 0, Net Worth: 1045.8769614596035\n",
            "Step: 76, Balance: 1045.8769614596035, Position: 0, Net Worth: 1045.8769614596035\n",
            "Step: 77, Balance: 1045.8769614596035, Position: 0, Net Worth: 1045.8769614596035\n",
            "Step: 78, Balance: 1045.8769614596035, Position: 0, Net Worth: 1045.8769614596035\n",
            "Step: 79, Balance: 86.92458158545068, Position: 10.0, Net Worth: 1045.8769614596035\n",
            "Step: 80, Balance: 86.92458158545068, Position: 10.0, Net Worth: 1137.991979855993\n",
            "Step: 81, Balance: 1025.1096482639712, Position: 0, Net Worth: 1025.1096482639712\n",
            "Step: 82, Balance: 1025.1096482639712, Position: 0, Net Worth: 1025.1096482639712\n",
            "Step: 83, Balance: 1025.1096482639712, Position: 0, Net Worth: 1025.1096482639712\n",
            "Step: 84, Balance: 64.23678078601245, Position: 10.0, Net Worth: 1025.1096482639712\n",
            "Step: 85, Balance: 64.23678078601245, Position: 10.0, Net Worth: 1184.945195444077\n",
            "Step: 86, Balance: 1064.241832383837, Position: 0, Net Worth: 1064.241832383837\n",
            "Step: 87, Balance: 17.739260480538647, Position: 11.0, Net Worth: 1064.241832383837\n",
            "Step: 88, Balance: 17.739260480538647, Position: 11.0, Net Worth: 1088.6621002837921\n",
            "Step: 89, Balance: 1081.3175616343906, Position: 0, Net Worth: 1081.3175616343906\n",
            "Step: 90, Balance: 1081.3175616343906, Position: 0, Net Worth: 1081.3175616343906\n",
            "Step: 91, Balance: 1081.3175616343906, Position: 0, Net Worth: 1081.3175616343906\n",
            "Step: 92, Balance: 1081.3175616343906, Position: 0, Net Worth: 1081.3175616343906\n",
            "Step: 93, Balance: 1081.3175616343906, Position: 0, Net Worth: 1081.3175616343906\n",
            "Step: 94, Balance: 1081.3175616343906, Position: 0, Net Worth: 1081.3175616343906\n",
            "Step: 95, Balance: 1081.3175616343906, Position: 0, Net Worth: 1081.3175616343906\n",
            "Step: 96, Balance: 1081.3175616343906, Position: 0, Net Worth: 1081.3175616343906\n",
            "Step: 97, Balance: 77.16848453178774, Position: 9.0, Net Worth: 1081.3175616343906\n",
            "Step: 98, Balance: 1011.551142957131, Position: 0, Net Worth: 1011.551142957131\n",
            "Step: 99, Balance: 1011.551142957131, Position: 0, Net Worth: 1011.551142957131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PySimpleGUIWeb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXEuuT5e6PN3",
        "outputId": "6f15f464-fb37-4f68-ba58-84ba6eef57ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PySimpleGUIWeb\n",
            "  Downloading PySimpleGUIWeb-0.39.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting remi<=2020.3.10 (from PySimpleGUIWeb)\n",
            "  Downloading remi-2020.3.10-py3-none-any.whl.metadata (17 kB)\n",
            "Downloading PySimpleGUIWeb-0.39.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading remi-2020.3.10-py3-none-any.whl (505 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.1/505.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: remi, PySimpleGUIWeb\n",
            "Successfully installed PySimpleGUIWeb-0.39.0 remi-2020.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D6xfd1ap7HWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Warehouse Environment Simulation Logic\n",
        "class WarehouseEnv:\n",
        "    def __init__(self, grid_size=10, items=None):\n",
        "        self.grid_size = grid_size\n",
        "        self.robot_pos = [0, 0]  # Starting position of the robot\n",
        "        self.items = items or [[5, 5], [2, 8], [8, 3]]  # Positions of items\n",
        "\n",
        "    def reset(self):\n",
        "        self.robot_pos = [0, 0]\n",
        "        self.items = [[5, 5], [2, 8], [8, 3]]  # Reset items\n",
        "        return np.array(self.robot_pos)\n",
        "\n",
        "    def step(self, action):\n",
        "        # Actions: 0 = Up, 1 = Down, 2 = Left, 3 = Right\n",
        "        if action == 0 and self.robot_pos[1] > 0:\n",
        "            self.robot_pos[1] -= 1\n",
        "        elif action == 1 and self.robot_pos[1] < self.grid_size - 1:\n",
        "            self.robot_pos[1] += 1\n",
        "        elif action == 2 and self.robot_pos[0] > 0:\n",
        "            self.robot_pos[0] -= 1\n",
        "        elif action == 3 and self.robot_pos[0] < self.grid_size - 1:\n",
        "            self.robot_pos[0] += 1\n",
        "\n",
        "        reward = -0.1\n",
        "        done = False\n",
        "        if self.robot_pos in self.items:\n",
        "            reward = 1\n",
        "            self.items.remove(self.robot_pos)\n",
        "\n",
        "        if not self.items:\n",
        "            done = True\n",
        "            reward = 10\n",
        "        return np.array(self.robot_pos), reward, done\n",
        "\n",
        "    def render(self):\n",
        "        grid = np.zeros((self.grid_size, self.grid_size), dtype=int)\n",
        "        for item in self.items:\n",
        "            grid[item[1], item[0]] = 2  # Item position marked with '2'\n",
        "        grid[self.robot_pos[1], self.robot_pos[0]] = 1  # Robot position marked with '1'\n",
        "        print(grid)\n",
        "\n",
        "def greedy_policy(robot_pos, items):\n",
        "    if not items:\n",
        "        return random.choice([0, 1, 2, 3])\n",
        "\n",
        "    distances = [np.linalg.norm(np.array(item) - np.array(robot_pos)) for item in items]\n",
        "    closest_item = items[np.argmin(distances)]\n",
        "\n",
        "    if closest_item[0] > robot_pos[0]:\n",
        "        return 3\n",
        "    elif closest_item[0] < robot_pos[0]:\n",
        "        return 2\n",
        "    elif closest_item[1] > robot_pos[1]:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Stock Trading Environment Simulation Logic\n",
        "class StockTradingEnv:\n",
        "    def __init__(self, data, initial_balance=1000):\n",
        "        self.data = data\n",
        "        self.current_step = 0\n",
        "        self.balance = initial_balance\n",
        "        self.position = 0\n",
        "        self.net_worth = self.balance\n",
        "        self.max_steps = len(data) - 1\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.balance = 1000\n",
        "        self.position = 0\n",
        "        self.net_worth = self.balance\n",
        "        return np.array([self.data[self.current_step], self.net_worth])\n",
        "\n",
        "    def step(self, action):\n",
        "        current_price = self.data[self.current_step]\n",
        "\n",
        "        if action == 1:  # Buy\n",
        "            self.position += self.balance // current_price\n",
        "            self.balance %= current_price\n",
        "        elif action == 2 and self.position > 0:  # Sell\n",
        "            self.balance += self.position * current_price\n",
        "            self.position = 0\n",
        "\n",
        "        self.net_worth = self.balance + self.position * current_price\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "        reward = self.net_worth - 1000\n",
        "        return np.array([self.data[self.current_step], self.net_worth]), reward, done\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"Step: {self.current_step}, Balance: {self.balance}, Position: {self.position}, Net Worth: {self.net_worth}\")\n",
        "\n",
        "# Simulation functions\n",
        "def run_warehouse_simulation():\n",
        "    env = WarehouseEnv()\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    print(\"Warehouse Simulation Starting...\\n\")\n",
        "    while not done:\n",
        "        action = greedy_policy(env.robot_pos, env.items)\n",
        "        state, reward, done = env.step(action)\n",
        "        env.render()\n",
        "        print(f\"Reward: {reward}\\n\")\n",
        "\n",
        "def run_stock_trading_simulation():\n",
        "    data = np.random.normal(100, 10, 100)  # Generate random stock prices\n",
        "    env = StockTradingEnv(data)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    print(\"Stock Trading Simulation Starting...\\n\")\n",
        "    while not done:\n",
        "        action = random.choice([0, 1, 2])  # 0=Hold, 1=Buy, 2=Sell\n",
        "        state, reward, done = env.step(action)\n",
        "        env.render()\n",
        "        print(f\"Reward: {reward}\\n\")\n",
        "\n",
        "# IPython Widgets Interface\n",
        "def start_warehouse():\n",
        "    clear_output(wait=True)\n",
        "    print(\"Starting Warehouse Simulation...\")\n",
        "    run_warehouse_simulation()\n",
        "\n",
        "def start_stock_trading():\n",
        "    clear_output(wait=True)\n",
        "    print(\"Starting Stock Trading Simulation...\")\n",
        "    run_stock_trading_simulation()\n",
        "\n",
        "warehouse_button = widgets.Button(description=\"Start Warehouse Navigation\")\n",
        "warehouse_button.on_click(lambda x: start_warehouse())\n",
        "\n",
        "trading_button = widgets.Button(description=\"Start Stock Trading\")\n",
        "trading_button.on_click(lambda x: start_stock_trading())\n",
        "\n",
        "display(warehouse_button, trading_button)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "af133bb3003e433db124cb478a9d0153",
            "92849633aab04dc89f979377096b10da",
            "ec6f0bf9a7614f2ca62f9de6c916a0e6",
            "b0058d589dcc4618a010477ff0316111",
            "cbeb6fd0a6414ec998f37c959ea1f996",
            "e14d3cb0835e4738bda88015160feceb"
          ]
        },
        "id": "Xhd0OuBC7Hl_",
        "outputId": "c6facb4a-5bc7-40f0-fcc7-eace104e2e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Warehouse Simulation...\n",
            "Warehouse Simulation Starting...\n",
            "\n",
            "[[0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: 1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: 1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: -0.1\n",
            "\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Reward: 10\n",
            "\n"
          ]
        }
      ]
    }
  ]
}